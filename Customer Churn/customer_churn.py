# -*- coding: utf-8 -*-
"""Customer churn.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DBMYcP_gTnaG1GC_7wNovSz5TJ-KDdrs

# **Importing libraries**
"""

from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score
from sklearn.preprocessing import OneHotEncoder
import matplotlib.pyplot as plt
from sklearn.linear_model import LogisticRegression
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler
import seaborn as sns
import pandas as pd
import numpy as np
from sklearn.utils import shuffle
from matplotlib.pyplot import figure

"""# **Importing Dataset**"""

from google.colab import drive
drive.mount('/content/drive')

train_df = pd.read_csv('/content/drive/MyDrive/Customer /train/customer_churn_dataset-training-master.csv')

test_df = pd.read_csv('/content/drive/MyDrive/Customer /test/customer_churn_dataset-testing-master.csv')

df = pd.concat([train_df, test_df], axis = 0)

df = shuffle(df, random_state=42)

"""# **Data Preproccessing**

# **EDA**
"""

df.head(20)

df.info()

"""1.Remove unnecessary columns"""

df.drop(columns='CustomerID', inplace=True)

"""2.Missing values"""

print(f"Missinng value count of Train dataset:\n {df.isna().sum()}")

Clean_df = df.dropna()

Clean_df.shape

"""There is` no missing value` in Train dataset.

3.Duplicates
"""

Clean_df.duplicated().sum()

"""4.Converting Data type"""

columns_need_encoding = [column for column in Clean_df if Clean_df[column].dtype =="object"]
Clean_df = pd.get_dummies(Clean_df, columns = columns_need_encoding)

Clean_df.head()

Clean_df.info()

"""5.Scaling Data"""

column_need_scaling = [column for column in Clean_df if
                      (('int' in str(Clean_df[column].dtype)) or ('float' in str(Clean_df[column].dtype))) and
                      Clean_df[column].nunique() > 2]
scaler = StandardScaler()
Clean_df[column_need_scaling] = scaler.fit_transform(Clean_df[column_need_scaling])
Clean_df.head()

"""6.Outliers"""

# Assuming data is your DataFrame (Clean_df) and you want to boxplot all columns
data = Clean_df

# Get the column names
column_names = data.columns

# Create a boxplot with x-axis labeled by column names
plt.figure(figsize=(12, 6))
boxplot = plt.boxplot(data.values, notch=True, vert=True, patch_artist=True, labels=column_names)

plt.title('Boxplot of features in Dataset')
plt.xlabel('Columns')
plt.ylabel('Values')

# Rotate x-axis labels for better readability
plt.xticks(rotation=45, ha='right')  # Adjust the rotation angle as needed

# Adjust layout to prevent clipping of labels
plt.tight_layout()

plt.show()

"""# **Data Analysis**"""

sns.set(style="whitegrid", palette="pastel")

# Plotting the countplot
plt.figure(figsize=(6, 4))
sns.countplot(x='Churn', data=Clean_df, palette=['#66c2ff', '#ff6666'])  # Customizing palette for better contrast

# Adding labels and title
plt.title('Churn Distribution', fontsize=16)
plt.xlabel('Churn', fontsize=14)
plt.ylabel('Count', fontsize=14)

# Show the plot
plt.show()

sns.set(style="whitegrid", palette="pastel")

# Plotting the histogram
plt.figure(figsize=(10, 6))
sns.histplot(x='Age', hue='Churn', data=Clean_df, bins=20, kde=False, multiple="stack", edgecolor='w')

# Adding labels and title
plt.title('Age Distribution by Churn', fontsize=16)
plt.xlabel('Age', fontsize=14)
plt.ylabel('Count', fontsize=14)

# Adding legend
plt.legend(title='Churn', loc='upper right', labels=['No Churn', 'Churn'])

# Show the plot
plt.show()

sns.set(style="whitegrid", palette="pastel")

# Plotting the countplot
plt.figure(figsize=(8, 6))
sns.countplot(x='Gender_Female', hue='Churn', data=Clean_df, palette=['#66c2ff', '#ff6666'])

# Adding labels and title
plt.title('Gender Distribution by Churn', fontsize=16)
plt.xlabel('Gender (Female)', fontsize=14)
plt.ylabel('Count', fontsize=14)

# Adding legend
plt.legend(title='Churn', loc='upper right', labels=['No Churn', 'Churn'])

# Show the plot
plt.show()

sns.set(style="whitegrid", palette="pastel")

# Plotting the countplot
plt.figure(figsize=(8, 6))
sns.countplot(x='Gender_Male', hue='Churn', data=Clean_df, palette=['#66c2ff', '#ff6666'])

# Adding labels and title
plt.title('Gender Distribution by Churn', fontsize=16)
plt.xlabel('Gender (Male)', fontsize=14)
plt.ylabel('Count', fontsize=14)

# Adding legend
plt.legend(title='Churn', loc='upper right', labels=['No Churn', 'Churn'])

# Show the plot
plt.show()

sns.set(style="whitegrid", palette="pastel")

# Plotting the histplot
plt.figure(figsize=(10, 6))
sns.histplot(x='Usage Frequency', hue='Churn', data=Clean_df, bins=20, kde=False, multiple="stack", palette=['#66c2ff', '#ff6666'])

# Adding labels and title
plt.title('Usage Frequency by Churn', fontsize=16)
plt.xlabel('Usage Frequency', fontsize=14)
plt.ylabel('Count', fontsize=14)

# Adding legend
plt.legend(title='Churn', loc='upper right', labels=['No Churn', 'Churn'])

# Show the plot
plt.show()

sns.set(style="whitegrid", palette="pastel")

# Calculate the percentage of churn for each number of support calls
percentage_churn = df.groupby('Support Calls')['Churn'].mean() * 100

# Plotting the bar plot with rotated x-labels
plt.figure(figsize=(10, 6))
ax = sns.barplot(x=percentage_churn.index, y=percentage_churn.values, color='#66c2ff')  # Customizing color

# Adding labels and title
plt.title('Churn Percentage by Number of Support Calls', fontsize=16)
plt.xlabel('Number of Support Calls', fontsize=14)
plt.ylabel('Churn Percentage', fontsize=14)

# Rotate x-labels for better readability
ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')

# Show the plot
plt.show()

"""# **Model**"""

X = Clean_df.drop(["Churn"], axis = 1)
y = Clean_df["Churn"]

X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, test_size = 0.2)

Model = RandomForestClassifier(n_estimators= 500,
                               max_features='sqrt',
                               min_samples_leaf= 3,
                               min_samples_split= 5,
                               max_leaf_nodes= 100)

Model.fit(X_train, y_train)
Model.score(X_test, y_test)

y_pred = Model.predict(X_test)
print(classification_report(y_test, y_pred))

cm = confusion_matrix(y_test, y_pred)


sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", cbar=False)
plt.xlabel("Predicted")
plt.ylabel("True")
plt.show()

feature_importance = Model.feature_importances_

sorted_idx = np.argsort(feature_importance)[::-1]

plt.figure(figsize=(10, 5))
sns.barplot(x=feature_importance[sorted_idx], y=X.columns[sorted_idx])
plt.xlabel('Feature Importance')
plt.ylabel('Features')
plt.title('Importance of each feature')
plt.show()

"""# Decision Tree"""

from sklearn.tree import DecisionTreeClassifier


param_grid = {'max_leaf_nodes': range(4,9)}
grid = GridSearchCV(DecisionTreeClassifier(random_state=0), param_grid=param_grid, cv=8)
grid.fit(X_train, y_train)

grid.score(X_test, y_test)

all_params_tried = grid.cv_results_['params']
print("All Parameters Tried:")
for params in all_params_tried:
    print(params)

print("Best Validation Score:", grid.best_params_ )